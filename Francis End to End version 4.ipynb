{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a74b426-5d2c-476f-a538-24260be719bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Details QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b96ce50-8a39-481f-b724-52e92f462111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import create_tagging_chain_pydantic\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.agents.agent_toolkits import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36bbe172-3ce5-4ae1-b9d9-d568b1560a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "__import__('pysqlite3')\n",
    "import sys\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a00abee-9260-49d8-a2e8-d08ee7aac156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "api_key = os.getenv(\"OPENAI_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e0a59c-87f5-4808-b9c1-f6b430cad781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", openai_api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed0aa117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"raw_data/one_day_test.csv\")\n",
    "all_available_countries = df['visited_countries'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff3a15c-bd79-4097-843a-cd1172ea2853",
   "metadata": {},
   "source": [
    "# stage analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aafec29",
   "metadata": {},
   "source": [
    "## interest extraction and sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44182c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class user_interests(BaseModel):\n",
    "    interest: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"Any experiances, interests, places or activities the user has expressed an interest in. Leave blank if none are mentioned\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94014d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_tagging_chain_pydantic(user_interests, llm)\n",
    "res = chain.run('User: i want to go hiking and surfing in morocco')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c0ef097",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_interests(interest='hiking, surfing, morocco')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise the found itineraries using map-reduce and then reduce the resulting summaries to rank \n",
    "# how well they relate to the user interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4802f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map prompt\n",
    "def map_prompt(interests):\n",
    "    interests = \", \".join(interests_list)\n",
    "\n",
    "    intermediate_template = f\"\"\"Based on this list of docs, please identify the itinerary name, tour length, travel style, physical grading, an summary of the itinerary and this list of interests: {interests}.\n",
    "    If one or more of the interests is not mentioned this include this in the answer.\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    map_template = \"\"\"The following is a set of documents\n",
    "    {docs}\n",
    "    \"\"\"\n",
    "    map_template += intermediate_template\n",
    "\n",
    "    map_prompt = PromptTemplate.from_template(map_template)\n",
    "    return map_prompt\n",
    "\n",
    "def first_reduce_prompt():\n",
    "    # Reduce\n",
    "    reduce_template = \"\"\"The following is set of summaries:\n",
    "    {doc_summaries}\n",
    "    Take these and distill it into a final, consolidated summary of the main themes. \n",
    "    Helpful Answer:\"\"\"\n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    return reduce_prompt\n",
    "\n",
    "# Reduce\n",
    "def second_reduce_prompt(interests):\n",
    "    interests = \", \".join(interests_list)\n",
    "\n",
    "    intermediate_template = f\"\"\"Take these and rank them based on the following user interests: {interests}.\n",
    "    Return the origional summary along with a reason for ranking each itinerary based on their interests.\n",
    "    Refer to the user as - you.\n",
    "    Helpful Answer:\"\"\"\n",
    "    \n",
    "    reduce_template = \"\"\"\n",
    "    You are an AI travel agent speaking to a user. The following is set of summaries that fits the users basic travel needs:\n",
    "    {doc_summaries}\n",
    "    \"\"\"\n",
    "    reduce_template += intermediate_template\n",
    "    \n",
    "    reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "    return reduce_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map\n",
    "map_chain = LLMChain(llm=llm, prompt=map_prompt())\n",
    "\n",
    "# Run chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=first_reduce_prompt())\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "# Combining documents by mapping a chain over them, then combining results\n",
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    # Map chain\n",
    "    llm_chain=map_chain,\n",
    "    # Reduce chain\n",
    "    reduce_documents_chain=reduce_documents_chain, #_documents\n",
    "    # The variable name in the llm_chain to put the documents in\n",
    "    document_variable_name=\"docs\",\n",
    "    # Return the results of the map steps in the output\n",
    "    return_intermediate_steps=False,\n",
    ")\n",
    "\n",
    "# list initial itinerary summaries\n",
    "text_vars = []\n",
    "\n",
    "for i in found_itineraries    \n",
    "    loader = TextLoader(i)\n",
    "    docs = loader.load()\n",
    "    itinerary_summary = map_reduce_chain.run(docs)\n",
    "    text_vars.append(itinerary_summary)\n",
    "\n",
    "    \n",
    "# Reduce\n",
    "# final Reduce chain\n",
    "reduce_chain = LLMChain(llm=llm, prompt=second_reduce_prompt())\n",
    "\n",
    "# Takes a list of documents, combines them into a single string, and passes this to an LLMChain\n",
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"doc_summaries\"\n",
    ")\n",
    "\n",
    "# Combines and iteravely reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")\n",
    "\n",
    "\n",
    "reduced = reduce_documents_chain.run(text_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be6c8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c2413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94631b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d70a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b4a12c6",
   "metadata": {},
   "source": [
    "## final stage analyser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff197d79-e492-4555-8613-da68ab2e9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TravelDetails(BaseModel):\n",
    "    introduction: Optional[bool] = Field(\n",
    "        False,\n",
    "        description=\"Has francis introducted himself and asked if the user is interested in a group tour.\",\n",
    "    )\n",
    "    qualification: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"Did the user confirm they are looking for a group tour or answer positivley when asked. If the user asks about a trip assume the answer is yes\",\n",
    "        enum=[\"Yes\", \"No\", \"Unsure\"]\n",
    "    )\n",
    "    country: Optional[str] = Field(\n",
    "        \"\",\n",
    "        description=\"This is the name of the country the user is wanting to visit. If they name a place within a country always return the country\",\n",
    "        enum=[\"Cambodia\", \"Vietnam\", \"Morocco\", \"USA\"]\n",
    "    )\n",
    "    \n",
    "    departing_after: Optional[str] = Field(\n",
    "        \"\",\n",
    "        description=\"This is the first date from which the user can depart. If the user gives a month assume this is the first of the month. If not year if given return 2023. In the format '%Y-%m-%d'\",\n",
    "    )\n",
    "    departing_before: Optional[str] = Field(\n",
    "        \"\",\n",
    "        description=\"This is the last date from which the user can depart. If the user gives a month assume this is the last day of the month. If not year if given return 2023. In the format '%Y-%m-%d'\",\n",
    "    )\n",
    "    max_budget: Optional[int] = Field(\n",
    "        0,\n",
    "        description=\"This is the maximun amount of money the user is looking to spend on their trip.\",\n",
    "    )\n",
    "    max_duration: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"This is the maximum duration of their trip.\"\n",
    "    )\n",
    "    min_duration: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"This is the minimum duration of their trip.\",\n",
    "    )\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69de78ba-1c58-433f-864c-03653cf31487",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_for_dict = {\"country\":\"what country are you looking to travel to?\",\n",
    "                \"max_budget\":\"how much are you looking to spend?\",\n",
    "                \"departing_after\":\"when are you looking to travel?\",\n",
    "                \"departing_before\":\"when are you looking to travel?\",\n",
    "                \"max_duration\":\"how long do you want your trip to be?\",\n",
    "                \"min_duration\":\"how long do you want your trip to be?\"\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d877fa78-435b-4627-a4f4-bbc916b006c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_what_is_empty(user_travel_details):\n",
    "    ask_for = []\n",
    "    # Check if fields are empty\n",
    "    for field, value in user_travel_details.dict().items():\n",
    "        if value in [None, \"\", 0]:  # You can add other 'empty' conditions as per your requirements\n",
    "            ask_for.append(ask_for_dict[field])\n",
    "    \n",
    "    if 'what country are you looking to travel to?' in ask_for:\n",
    "        ask_for.remove('what country are you looking to travel to?')\n",
    "        ask_for.insert(0, 'what country are you looking to travel to?')\n",
    "    elif 'how much are you looking to spend?' in ask_for:\n",
    "        ask_for.remove('how much are you looking to spend?')\n",
    "        ask_for.insert(0, 'how much are you looking to spend?')\n",
    "\n",
    "    \n",
    "    return ask_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b4a599e-ebe3-4c75-a65f-adbb83cd4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the response and adding it\n",
    "def add_non_empty_details(current_details: TravelDetails, new_details: TravelDetails):\n",
    "    non_empty_details = {k: v for k, v in new_details.dict().items() if v not in [False, None, \"\"]}\n",
    "    updated_details = current_details.copy(update=non_empty_details)\n",
    "    return updated_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a27b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom function to find the first non-null value in columns 9 to the end of the df \n",
    "# used for finding the costs\n",
    "def find_first_non_null(row):\n",
    "    for value in row[12:]:  # Slice from the 9th column to the end\n",
    "        if not pd.isna(value):\n",
    "            return value\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a717df4f-854e-449e-aaec-0989caef0f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_df(df, user_travel_details):\n",
    "    trip_details_dict = user_travel_details.dict()\n",
    "    filled_out_dictionary = {k: v for k, v in user_travel_details.dict().items() if v not in [False, None, \"\",0]}\n",
    "\n",
    "    # convert dates to datetime format\n",
    "    df['duration'] = df['duration'].str.replace(' days', '').astype(int)\n",
    "    df['start_date'] = pd.to_datetime(df['start_date'], format='%Y-%m-%d')\n",
    "    \n",
    "    # Apply the custom function to each row to find cost\n",
    "    df['first_non_null'] = df.apply(find_first_non_null, axis=1)\n",
    "\n",
    "    # Filtering the DataFrame\n",
    "    filtered_df = df.copy()  # Make a copy of the original DataFrame to keep it intact\n",
    "    \n",
    "    # Iterate through the list of potential inputs\n",
    "    for input_column in filled_out_dictionary.keys():\n",
    "        if input_column == 'country':\n",
    "            filtered_df = filtered_df[filtered_df['visited_countries'] == trip_details_dict[\"country\"]]\n",
    "        elif input_column == 'max_budget':\n",
    "            filtered_df = filtered_df[filtered_df['first_non_null'] <= trip_details_dict[\"max_budget\"]]\n",
    "        elif input_column == 'min_budget':\n",
    "            filtered_df = filtered_df[filtered_df['first_non_null'] >= trip_details_dict[\"min_budget\"]]\n",
    "        elif input_column == 'departing_after':\n",
    "            filtered_df = filtered_df[filtered_df['start_date'] >= trip_details_dict[\"departing_after\"]]\n",
    "        elif input_column == 'departing_before':\n",
    "            filtered_df = filtered_df[filtered_df['start_date'] <= trip_details_dict[\"departing_before\"]]\n",
    "        elif input_column == 'max_duration':\n",
    "            filtered_df = filtered_df[filtered_df['duration'] <= trip_details_dict[\"max_duration\"]]\n",
    "        elif input_column == 'min_duration':\n",
    "            filtered_df = filtered_df[filtered_df['duration'] >= trip_details_dict[\"min_duration\"]]\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebb7794c-9d35-4641-942b-a93cbf292799",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItineraryDetails(BaseModel):\n",
    "    itinerary_name: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"The name of the itinerary the user has decided to take not the country\",\n",
    "    )\n",
    "    itinerary_start_date: Optional[str] = Field(\n",
    "        ...,\n",
    "        description=\"The start date of the itinerary the user has decided to take. This is an exact date\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa731c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17a9db27",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_of_interest: Optional[str] = Field(\n",
    "        \"\",\n",
    "        description=\"This can be a city, place or attraction that the used has said they want to visit and should be used in addition to country not instead of\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "307ed380-488d-4d0e-a427-ee75434897f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_dates = [\"06/04/2023\",\"13/04/2023\",\"20/04/2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ba535b-41fe-4878-8327-006324af7c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"www.affiliate_link_to_website.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cdfc3fa-a10d-4f9e-9465-47e16dae4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "asked_for = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650f38a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b9b11f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that can be used in the info gathering prompt\n",
    "def prompt_amendments(ask_for, filtered_df, found_itineraries):\n",
    "    if ask_for[0] == 'how much are you looking to spend?':\n",
    "        min_budget = filtered_df['first_non_null'].min()\n",
    "        mean_budget = filtered_df['first_non_null'].mean()\n",
    "        return f'In your answer tell the user there are {len(found_itineraries)} itineraries that fit their needs.\\\n",
    "        The minimim trip cost is {min_budget} and the average tripcost is {mean_budget} to their destination.'\n",
    "    if ask_for[0] == 'when are you looking to travel?':\n",
    "         print('The question is about when to travel')\n",
    "    if ask_for[0] == 'how long do you want your trip to be?':\n",
    "         print('The question is about the duration')\n",
    "    if ask_for[0] == 'what country are you looking to travel to?':\n",
    "         print('The question is about where they want to travel to')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5102c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdb5f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info gathering promtps\n",
    "# Info gathering stage when there are still trip details to ask for\n",
    "def info_gathering_prompt(ask_for, found_itineraries, filtered_df):\n",
    "    if len(ask_for) == 6:\n",
    "        PROMPT_TEMPLATE = f\"\"\"You are currently in the detail gathering phase of the conversation and are trying to get detail of the users trip to help find the the perfect trip. \n",
    "            If the user has just asked a follow up question in the conversation history, answer it.\n",
    "            Once you have answered their question ALWAYS ask the user the following question to gather the required information.\n",
    "            Follow up question:\n",
    "            {ask_for[0]}\"\"\"\n",
    "    else:\n",
    "        PROMPT_TEMPLATE = f\"\"\"You are currently in the trip detail phase of the conversation and are trying to get detail of the users trip to help find the the perfect trip. \n",
    "            If the user has just asked a follow up question in the conversation history, answer it.\n",
    "            Once you have answered their question ALWAYS ask the user the following question to gather the required information.\n",
    "            Follow up question:\n",
    "            {ask_for[0]}\n",
    "            \"\"\"\n",
    "        # {prompt_amendments(ask_for, filtered_df, found_itineraries)} \n",
    "    return PROMPT_TEMPLATE\n",
    "    \n",
    "\n",
    "# All the details are gathered and we're presenting a solution, list of available itineraries\n",
    "def solution_presentation_prompt(found_itineraries, df):\n",
    "    summary = \"\"\n",
    "    for itinerary in found_itineraries:\n",
    "        filtered_df = df[df['tour_name'] == itinerary]\n",
    "        summary += f'Itinerary: {filtered_df[\"tour_name\"].values[0]}\\n'\n",
    "        summary += f'Tour description: {filtered_df[\"tour_description\"].values[0]}\\n'\n",
    "        summary += f'Link: {filtered_df[\"url\"].values[0]}\\n\\n'\n",
    "    \n",
    "    conversation_stage = f\"\"\"Thank the user for providing the details. \n",
    "        Based on all the users needs here is the list of itineraries and a summary that fit their needs:\\n{summary} \n",
    "        Present the itinerary or itineraries to the user. \n",
    "        \"\"\"\n",
    "    # text summarisation needed for the above\n",
    "    return conversation_stage\n",
    "\n",
    "\n",
    "# all trip details are gathered and the clients have decided on an itinerary\n",
    "def available_dates_prompt(dates_text):\n",
    "        conversation_stage = f\"\"\"\n",
    "            The user has now decided on on the itinerary would like. We now need to check what dates they would like to travel on. The following dates are availab: \n",
    "            {dates_text}.\n",
    "            Ask the user to pick a desired departure date.\"\"\"\n",
    "        return conversation_stage\n",
    "\n",
    "# all trip details are gathered, the clients have decided on an itinerary and have a departure date\n",
    "def url_presentation_prompt(URL):\n",
    "        conversation_stage = f\"\"\"\n",
    "        The user now has an itinerary and the dates they want to travel. \n",
    "        You are not booking the trip for the user, just share the companies url: {URL}\"\"\"\n",
    "        return conversation_stage\n",
    "\n",
    "\n",
    "# still in the info gathering stage but there are no available itineraries based on preferences\n",
    "def no_results_prompt(user_travel_details, new_user_travel_details):\n",
    "    old_keys = new_user_travel_details.dict().keys()\n",
    "    new_keys = new_user_travel_details.dict().keys()\n",
    "    last_question = [x for x in new_keys if x not in old_keys]\n",
    "    conversation_stage = f\"\"\"\n",
    "        The user has provided details of their trip but unfortunatley there are no itineraries that match their needs. \n",
    "        Explain this to the user and higlight they need to look at alternate: {\", \".join(last_question)}\"\"\"\n",
    "    return conversation_stage\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57b23452-7d55-4a00-8434-224cb58ca164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conversation_stage(conversation_history, user_travel_details, user_itinerary_details):\n",
    "\n",
    "    conversation_history = \"\\n\".join(conversation_history)\n",
    "\n",
    "    # extract travel details chain\n",
    "    chain = create_tagging_chain_pydantic(TravelDetails, llm)\n",
    "    res = chain.run(conversation_history)\n",
    "    new_user_travel_details = add_non_empty_details(user_travel_details, res)\n",
    "    ask_for = check_what_is_empty(new_user_travel_details)\n",
    "\n",
    "    #load df\n",
    "    df = pd.read_csv(\"raw_data/one_day_test.csv\")\n",
    "    \n",
    "    # check number of unique itineraries\n",
    "    filtered_df = get_filtered_df(df, new_user_travel_details)\n",
    "    found_itineraries = filtered_df['tour_name'].unique()\n",
    "    \n",
    "    if len(filtered_df) == 0:\n",
    "        conversation_stage = no_results_prompt(user_travel_details, new_user_travel_details)                        \n",
    "        return conversation_stage, new_user_travel_details\n",
    "\n",
    "\n",
    "#     if len(ask_for) == 0:\n",
    "#         # extract itinerary details chain\n",
    "#         chain = create_tagging_chain_pydantic(ItineraryDetails, llm)\n",
    "#         res = chain.run(conversation_history)\n",
    "#         user_itinerary_details = add_non_empty_details(user_itinerary_details, res)\n",
    "#         print(user_itinerary_details)\n",
    "\n",
    "    # # check if we have all validated details and if we have an itinerary from the user. \n",
    "    # # We then need present the list of dates and have the client decide\n",
    "    if len(ask_for) == 0 and user_itinerary_details.itinerary_name in found_itineraries and user_itinerary_details.itinerary_start_date in available_dates:\n",
    "        print('all details gathered, itinerary decided and date sorted')\n",
    "        conversation_stage = url_presentation_prompt(URL)                        \n",
    "        return conversation_stage, new_user_travel_details\n",
    "\n",
    "\n",
    "    # # check if we have all validated details and if we have an itinerary from the user. \n",
    "    # # We then need present the list of dates and have the client decide\n",
    "    elif len(ask_for) == 0 and user_itinerary_details.itinerary_name in found_itineraries:\n",
    "        print(\"Itinerary selected! summarise the itineraries...\")\n",
    "        dates_text = \"\\n\".join(available_dates)\n",
    "        conversation_stage = available_dates_prompt(dates_text)                        \n",
    "        return conversation_stage, new_user_travel_details\n",
    "\n",
    "    # if we have all the validated details we need to present the list of itineraries and have the client decide\n",
    "    elif len(ask_for) == 0 and len(found_itineraries) > 0:\n",
    "        print(\"All details gathered! summarise the itineraries...\")\n",
    "        conversation_stage = solution_presentation_prompt(found_itineraries, df)   \n",
    "        return conversation_stage, new_user_travel_details\n",
    "    \n",
    "    if user_travel_details.dict()['qualification'] == 'no':\n",
    "        conversation_stage = \"The user is not interested in a group tour so politely end the conversation. Ask them to come back if they ever are\"\n",
    "    elif user_travel_details.dict()['qualification'] == 'Unsure':\n",
    "        conversation_stage = \"Explain what a group tour is. End your response by asking the user if they are interested in a group tour?\"\n",
    "    else:\n",
    "        conversation_stage = info_gathering_prompt(ask_for, found_itineraries, filtered_df)\n",
    "        asked_for.append(ask_for[0])\n",
    "\n",
    "    return conversation_stage, new_user_travel_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2a6846-d3fd-414a-a29d-b9c2546980e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b929bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumarization_tool(input=\"\"):\n",
    "    return 'a 15 day itinerary through morocco.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f4ca2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import PythonAstREPLTool\n",
    "df = pd.read_csv(\"raw_data/one_day_test.csv\")\n",
    "\n",
    "class PythonInputs(BaseModel):\n",
    "    query: str = Field(description=\"code snippet to run\")\n",
    "        \n",
    "repl = PythonAstREPLTool(locals={\"df\": df}, \n",
    "                         name=\"multi_county_query\",\n",
    "                         description=\"useful for answering questions about multiple country costs e.g. average trip cost to peru\",\n",
    "                         args_schema=PythonInputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e854c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def get_tools():          \n",
    "    #tru start\n",
    "    class DocumentInput(BaseModel):\n",
    "        question: str = Field()\n",
    "\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\", openai_api_key=api_key)\n",
    "\n",
    "    tools = []\n",
    "    \n",
    "    files = []\n",
    "    for file in glob.glob('raw_data/itinerary_text/*'):\n",
    "        file_dict = {'name': file.split(\"/\")[-1].replace('.txt','').replace('& ','').replace(':','').replace(' ','_'),\n",
    "                    \"path\": file}\n",
    "        files.append(file_dict)\n",
    "\n",
    "    for file in files[:10]:\n",
    "        loader = TextLoader(file[\"path\"])\n",
    "        pages = loader.load_and_split()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "        docs = text_splitter.split_documents(pages)\n",
    "        embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "        retriever = FAISS.from_documents(docs, embeddings).as_retriever()\n",
    "\n",
    "        # Wrap retrievers in a Tool\n",
    "        tools.append(\n",
    "            Tool(\n",
    "                args_schema=DocumentInput,\n",
    "                name=file[\"name\"],\n",
    "                description=f\"needed when you want to answer questions about {file['name']} itinerary\",\n",
    "                func=RetrievalQA.from_chain_type(llm=llm, retriever=retriever),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "#     tools.append(PythonAstREPLTool(locals={\"df\": df}, \n",
    "#                          name=\"multi_county_query\",\n",
    "#                          description=\"useful for answering questions about multiple country costs e.g. average trip cost to peru\",\n",
    "#                          args_schema=PythonInputs))\n",
    "        \n",
    "    return tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26eb63c7-562a-49d5-aa52-f1d0de09915d",
   "metadata": {},
   "source": [
    "# Sales Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f340dfd2-c7db-439c-9afa-aaa341b25c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import OpenAIFunctionsAgent, AgentExecutor\n",
    "from langchain.agents import Tool\n",
    "from langchain.schema.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5a47031-84b8-421a-a564-93e196bfb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SALES_AGENT_TOOLS_PROMPT = \"\"\"\n",
    "Never forget your name is Francis. You work as a Travel Agent.\n",
    "You work at company named Francis. Francis's business is the following: Francis is a context aware AI travel agent that works on finding users their dream group tour holiday.\n",
    "You are contacting a potential prospect in order to find them a group toup holiday.\n",
    "Your means of contacting the prospect is live chat.\n",
    "\n",
    "Keep your responses in short length to retain the user's attention. Never produce lists, just answers.\n",
    "\n",
    "Always think about the following conversation stage you are at before answering:\n",
    "\n",
    " - {conversation_stage}\n",
    "\n",
    "You MUST respond according to the previous conversation history and the stage of the conversation you are at.\n",
    "If you get asked about an itinerary use the tools available to you, do not make up an answer. If you do not know the answer tell the user.\n",
    "Only generate one response at a time and act as Francis only!\n",
    "Do not add Francis: to your output.\n",
    "\n",
    "Previous conversation history:\n",
    "{conversation_history}\n",
    "\n",
    "Begin!\n",
    "\"\"\"\n",
    "\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66d6c897-0d66-40f8-b23d-23f48643bb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_prompt(conversation_history, conversation_stage, SALES_AGENT_TOOLS_PROMPT):\n",
    "\n",
    "    conversation_history = \"\\n\".join(conversation_history)\n",
    "    \n",
    "    \n",
    "    from langchain import LLMChain, PromptTemplate\n",
    "    prompt = PromptTemplate(\n",
    "                template=SALES_AGENT_TOOLS_PROMPT,\n",
    "                input_variables=[\n",
    "                    \"conversation_stage\",\n",
    "                    \"conversation_history\"\n",
    "                ],\n",
    "            )\n",
    "    \n",
    "    SALES_AGENT_TOOLS_PROMPT = prompt.format(conversation_stage=conversation_stage, \n",
    "                                     conversation_history=conversation_history)\n",
    "    \n",
    "    system_message = SystemMessage(\n",
    "            content=(SALES_AGENT_TOOLS_PROMPT\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "            system_message=system_message\n",
    "    )\n",
    "\n",
    "    return prompt\n",
    "# print(prompt.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "928fde58-12ae-49ff-a833-51645d0987bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 917, which is longer than the specified 500\n",
      "Created a chunk of size 830, which is longer than the specified 500\n",
      "Created a chunk of size 771, which is longer than the specified 500\n",
      "Created a chunk of size 559, which is longer than the specified 500\n",
      "Created a chunk of size 800, which is longer than the specified 500\n",
      "Created a chunk of size 710, which is longer than the specified 500\n",
      "Created a chunk of size 724, which is longer than the specified 500\n",
      "Created a chunk of size 902, which is longer than the specified 500\n",
      "Created a chunk of size 759, which is longer than the specified 500\n",
      "Created a chunk of size 762, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "# Define the tools\n",
    "tools = get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d9be55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import OpenAIMultiFunctionsAgent\n",
    "def run_francis(input, conversation_history, user_travel_details, user_itinerary_details):\n",
    "    llm = ChatOpenAI(temperature=0.9, model=\"gpt-3.5-turbo\", openai_api_key=api_key)\n",
    "    \n",
    "    user_input = f\"User: {input}\"\n",
    "\n",
    "    conversation_history.append(user_input)\n",
    "\n",
    "    conversation_stage, user_travel_details = check_conversation_stage(conversation_history, user_travel_details, user_itinerary_details)\n",
    "    \n",
    "    final_prompt = customize_prompt(conversation_history, conversation_stage, SALES_AGENT_TOOLS_PROMPT)\n",
    "    \n",
    "    # Create the agent\n",
    "    agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=final_prompt)\n",
    "    # agent = OpenAIMultiFunctionsAgent(llm=llm, tools=tools, prompt=final_prompt)\n",
    "    \n",
    "    # Run the agent with the actions\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=False, max_iterations=5)\n",
    "    #output = agent_executor.run(\"\")\n",
    "    \n",
    "    francis = agent_executor.run(input)\n",
    "    francis1 = f\"Francis: {francis}\"\n",
    "    conversation_history.append(francis1)\n",
    "\n",
    "    return francis, user_travel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e18bc7fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ad\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ad' is not defined"
     ]
    }
   ],
   "source": [
    "ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e0249-c67e-4c2e-8255-21d5194e5a77",
   "metadata": {},
   "source": [
    "# conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d04585d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7c880d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_travel_details = TravelDetails(introduction=False,\n",
    "                                qualification=\"\",\n",
    "                                country=\"\",\n",
    "                                departing_after=None,\n",
    "                                departing_before=None,\n",
    "                                max_budget=None,\n",
    "                                max_duration=None,\n",
    "                                min_duration=None,\n",
    "                                # places_of_interest=\"\"\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cc7f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_interests = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3efeac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_itinerary_details = ItineraryDetails(itinerary_name=\"\",\n",
    "                                itinerary_start_date=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0021a233-91d4-42c4-9b4c-af45f336c33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history = [\"Francis:  Hello, this is Francis from Francis Travel. Can i help you find a group tour today?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5281ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! I'm here to help you find the perfect group tour. What country are you looking to travel to?\n"
     ]
    }
   ],
   "source": [
    "human_input = \"yes\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692804d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_travel_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33c348cf-fa3f-4f67-9c24-11695dacfdf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Morocco is a wonderful country to visit. How much are you looking to spend on your group tour to Morocco?\n"
     ]
    }
   ],
   "source": [
    "human_input = \"Morocco\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1111ba04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! With a budget of £2000, there are a few group tour options available for your trip to Morocco. When are you looking to travel?\n"
     ]
    }
   ],
   "source": [
    "human_input = \"£2000\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "926c5ae0-442e-4b92-8e37-61aac6694190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing your travel month. Now, how long do you want your trip to be?\n"
     ]
    }
   ],
   "source": [
    "human_input = \"april 2024\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e68eb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All details gathered! summarise the itineraries...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m human_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetween 4 and 30 days\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m francis_output, user_travel_details \u001b[38;5;241m=\u001b[39m run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(francis_output)\n",
      "Cell \u001b[0;32mIn [30], line 21\u001b[0m, in \u001b[0;36mrun_francis\u001b[0;34m(input, conversation_history, user_travel_details, user_itinerary_details)\u001b[0m\n\u001b[1;32m     18\u001b[0m agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39magent, tools\u001b[38;5;241m=\u001b[39mtools, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#output = agent_executor.run(\"\")\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m francis \u001b[38;5;241m=\u001b[39m \u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m francis1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrancis: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfrancis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m conversation_history\u001b[38;5;241m.\u001b[39mappend(francis1)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chains/base.py:475\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    474\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    476\u001b[0m         _output_key\n\u001b[1;32m    477\u001b[0m     ]\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    481\u001b[0m         _output_key\n\u001b[1;32m    482\u001b[0m     ]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chains/base.py:282\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    283\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    284\u001b[0m final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    285\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[1;32m    286\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chains/base.py:276\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, include_run_info)\u001b[0m\n\u001b[1;32m    270\u001b[0m run_manager \u001b[38;5;241m=\u001b[39m callback_manager\u001b[38;5;241m.\u001b[39mon_chain_start(\n\u001b[1;32m    271\u001b[0m     dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    272\u001b[0m     inputs,\n\u001b[1;32m    273\u001b[0m )\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    275\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    278\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    281\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/agents/agent.py:1036\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1036\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1045\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1046\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/agents/agent.py:833\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m    830\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m--> 833\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/agents/openai_functions_agent/base.py:211\u001b[0m, in \u001b[0;36mOpenAIFunctionsAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, with_functions, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m messages \u001b[38;5;241m=\u001b[39m prompt\u001b[38;5;241m.\u001b[39mto_messages()\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_functions:\n\u001b[0;32m--> 211\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_messages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     predicted_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mpredict_messages(\n\u001b[1;32m    218\u001b[0m         messages,\n\u001b[1;32m    219\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    220\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:601\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[0;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     _stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(stop)\n\u001b[0;32m--> 601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_stop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:551\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[0;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    546\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    550\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m--> 551\u001b[0m     generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[1;32m    555\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:309\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    308\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    310\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    311\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    313\u001b[0m ]\n\u001b[1;32m    314\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:299\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 299\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/base.py:446\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n\u001b[1;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported:\n\u001b[0;32m--> 446\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/openai.py:339\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    337\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    338\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 339\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/openai.py:278\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs: t\u001b[38;5;241m.\u001b[39mAny, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: t\u001b[38;5;241m.\u001b[39mAny) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tenacity/__init__.py:406\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tenacity/__init__.py:351\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    349\u001b[0m is_explicit_retry \u001b[38;5;241m=\u001b[39m retry_state\u001b[38;5;241m.\u001b[39moutcome\u001b[38;5;241m.\u001b[39mfailed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(retry_state\u001b[38;5;241m.\u001b[39moutcome\u001b[38;5;241m.\u001b[39mexception(), TryAgain)\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry(retry_state\u001b[38;5;241m=\u001b[39mretry_state)):\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter(retry_state)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/tenacity/__init__.py:409\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    411\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/langchain/chat_models/openai.py:276\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_raw\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupplied_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[38;5;241m.\u001b[39msession_create_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mabs_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTIMEOUT_SECS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mTimeout(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequest timed out: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/lewagon/lib/python3.10/site-packages/urllib3/connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1275\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "human_input = \"between 4 and 30 days\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_input = \"how long is it?\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db329b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_input = \"What is the day by day summary?\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_input = \"Can you give me some more details?\"\n",
    "francis_output, user_travel_details = run_francis(human_input, conversation_history, user_travel_details, user_itinerary_details)\n",
    "print(francis_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd45d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
